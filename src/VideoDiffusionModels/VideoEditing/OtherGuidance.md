# 3.5 Other Guidance


P264  

![](../../assets/08-264.png)   

|ID|Year|Name|Note|Tags|Link|
|---|---|---|---|---|---|
||2023|InstructVid2Vid: Controllable Video Editing with Natural Language Instructions| - Generate ⟨instruction, video⟩ dataset using ChatGPT, BLIP and Tune-A-Video <br> - Train inflated Stable Diffusion for instruction-guided video editing |![](../../assets/08-266.png) 
||2023|Soundini: Sound-Guided Diffusion for Natural Video Editing|Sound-guided video editing | ![](../../assets/08-268.png) |
||2023|DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory||![](../../assets/08-269-3.png)|轨迹控制|
||2023|Collaborative Score Distillation for Consistent Visual Synthesis|| ![](../../assets/08-269-1.png)  |
||2023|Make-A-Protagonist: Generic Video Edigng with An Ensemble of Experts|| ![](../../assets/08-269-2.png) | 

P272

> &#x2705; showlab/Awesome-Video-Diffusion    

---------------------------------------
> 本文出自CaterpillarStudyGroup，转载请注明出处。
>
> https://caterpillarstudygroup.github.io/ImportantArticles/

